---
title: "R Notebook"
output: html_notebook
---

Chapter 5

```{r, eval=FALSE}
library(keras)
library(reticulate)
use_virtualenv("~/.virtualenvs/tensorflow_macos_venv/", required = TRUE )
py_module_available("tensorflow") 
library(tensorflow)
```


```{r, eval=TRUE}
library(tidyverse)
library(keras)
use_condaenv("r-reticulate")
```


```{r}
model <- keras_model_sequential() %>% 
  layer_conv_2d(filters = 32, kernel_size = c(3, 3), activation = "relu",
                input_shape = c(28, 28, 1)) %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu") %>% 
  layer_max_pooling_2d(pool_size = c(2, 2)) %>% 
  layer_conv_2d(filters = 64, kernel_size = c(3, 3), activation = "relu")
```


```{r}
summary(model)
```


```{r}
model <- model %>% 
  layer_flatten() %>% 
  layer_dense(units = 64, activation = "relu") %>% 
  layer_dense(units = 10, activation = "softmax")
```

We are going to do 10-way classification, so we use a final layer with 10 outputs and a softmax activation. Now here's what our network looks like:

```{r}
summary(model)
```


```{r, echo=TRUE, results='hide'}
mnist <- dataset_mnist()
c(c(train_images, train_labels), c(test_images, test_labels)) %<-% mnist

train_images <- array_reshape(train_images, c(60000, 28, 28, 1))
train_images <- train_images / 255

test_images <- array_reshape(test_images, c(10000, 28, 28, 1))
test_images <- test_images / 255

train_labels <- to_categorical(train_labels)
test_labels <- to_categorical(test_labels)

model %>% compile(
  optimizer = "rmsprop",
  loss = "categorical_crossentropy",
  metrics = c("accuracy")
)
              
system.time(model %>% fit(
  train_images, train_labels, 
  epochs = 5, batch_size=64
))
```

Let's evaluate the model on the test data:

```{r, echo=TRUE, results='hide'}
results <- model %>% evaluate(test_images, test_labels)
```

```{r}
results
```